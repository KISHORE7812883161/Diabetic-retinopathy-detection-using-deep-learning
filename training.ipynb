{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/souravs17031999/Retinal_blindness_detection_Pytorch/blob/master/training.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "4lVyi6I3wp9-"
      },
      "source": [
        "# Import the essentials"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "colab": {},
        "colab_type": "code",
        "id": "-H5XMQt5wp-B",
        "outputId": "8405258a-6edb-48ef-efde-fe87e9d38934"
      },
      "outputs": [
        {
          "ename": "ImportError",
          "evalue": "DLL load failed while importing _C: The specified module could not be found.",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[11], line 5\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m\n\u001b[1;32m----> 5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m data\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m nn\n",
            "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\torch\\utils\\__init__.py:8\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mweakref\u001b[39;00m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[1;32m----> 8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m      9\u001b[0m     backcompat \u001b[38;5;28;01mas\u001b[39;00m backcompat,\n\u001b[0;32m     10\u001b[0m     collect_env \u001b[38;5;28;01mas\u001b[39;00m collect_env,\n\u001b[0;32m     11\u001b[0m     data \u001b[38;5;28;01mas\u001b[39;00m data,\n\u001b[0;32m     12\u001b[0m     deterministic \u001b[38;5;28;01mas\u001b[39;00m deterministic,\n\u001b[0;32m     13\u001b[0m     hooks \u001b[38;5;28;01mas\u001b[39;00m hooks,\n\u001b[0;32m     14\u001b[0m )\n\u001b[0;32m     15\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbackend_registration\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     16\u001b[0m     generate_methods_for_privateuse1_backend,\n\u001b[0;32m     17\u001b[0m     rename_privateuse1_backend,\n\u001b[0;32m     18\u001b[0m )\n\u001b[0;32m     19\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcpp_backtrace\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m get_cpp_backtrace\n",
            "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\torch\\utils\\backcompat\\__init__.py:2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# mypy: allow-untyped-defs\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_C\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _set_backcompat_broadcast_warn\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_C\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _get_backcompat_broadcast_warn\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_C\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _set_backcompat_keepdim_warn\n",
            "\u001b[1;31mImportError\u001b[0m: DLL load failed while importing _C: The specified module could not be found."
          ]
        }
      ],
      "source": [
        "# Imports here\n",
        "from __future__ import print_function, division\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from torch.utils import data\n",
        "import torch\n",
        "from torch import nn\n",
        "from torch import optim\n",
        "import torchvision\n",
        "import torch.nn.functional as F\n",
        "from torchvision import datasets, transforms, models\n",
        "import torchvision.models as models\n",
        "from torch.utils.data.sampler import SubsetRandomSampler\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from skimage import io, transform\n",
        "import torch.utils.data as data_utils\n",
        "from PIL import Image, ImageFile\n",
        "import json\n",
        "from torch.optim import lr_scheduler\n",
        "import time\n",
        "import os\n",
        "import argparse\n",
        "import copy\n",
        "import pandas as pd\n",
        "ImageFile.LOAD_TRUNCATED_IMAGES = True\n",
        "import cv2\n",
        "# Import useful sklearn functions\n",
        "import sklearn\n",
        "from sklearn.metrics import cohen_kappa_score, accuracy_score\n",
        "\n",
        "import time\n",
        "from tqdm import tqdm_notebook\n",
        "\n",
        "import os\n",
        "print(os.listdir(\"../input\"))\n",
        "base_dir = \"../input/aptos2019-blindness-detection/\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Name: torch\n",
            "Version: 2.5.1+cpu\n",
            "Summary: Tensors and Dynamic neural networks in Python with strong GPU acceleration\n",
            "Home-page: https://pytorch.org/\n",
            "Author: PyTorch Team\n",
            "Author-email: packages@pytorch.org\n",
            "License: BSD-3-Clause\n",
            "Location: C:\\Users\\Kishore M\\AppData\\Roaming\\Python\\Python312\\site-packages\n",
            "Requires: filelock, fsspec, jinja2, networkx, setuptools, sympy, typing-extensions\n",
            "Required-by: torchaudio, torchvision\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING: Ignoring invalid distribution ~orch (C:\\Users\\Kishore M\\AppData\\Roaming\\Python\\Python312\\site-packages)\n"
          ]
        }
      ],
      "source": [
        "pip show torch\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "EHKTScVRwp-x",
        "outputId": "aa412cf4-4dcc-4fec-b2b3-1d39e21eb7ed"
      },
      "outputs": [],
      "source": [
        "print(os.listdir(\"../input/kernel4f121f3247\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "5yxnwe8jwp-2"
      },
      "outputs": [],
      "source": [
        "import seaborn as sns"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Mkb_neoqwp-6"
      },
      "source": [
        "# Loading Data + EDA"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
        "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
        "colab": {},
        "colab_type": "code",
        "id": "hkyWGmomwp-7"
      },
      "outputs": [],
      "source": [
        "train_csv = pd.read_csv('../input/aptos2019-blindness-detection/train.csv')\n",
        "test_csv = pd.read_csv('../input/aptos2019-blindness-detection/test.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "pkd7u6RRwp-9",
        "outputId": "7fdbb7a4-25c1-43c7-f6f2-d9787b1c7ba2"
      },
      "outputs": [],
      "source": [
        "print('Train Size = {}'.format(len(train_csv)))\n",
        "print('Public Test Size = {}'.format(len(test_csv)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "jgR8VptTwp_C",
        "outputId": "898edfe9-0fd2-4edc-c23a-14a3b5d295be"
      },
      "outputs": [],
      "source": [
        "train_csv.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "vgygoo4Vwp_F",
        "outputId": "dff17c47-0a34-45ce-ff5f-83fcf0463047"
      },
      "outputs": [],
      "source": [
        "counts = train_csv['diagnosis'].value_counts()\n",
        "class_list = ['No DR', 'Mild', 'Moderate', 'Severe', 'Proliferate']\n",
        "for i,x in enumerate(class_list):\n",
        "    counts[x] = counts.pop(i)\n",
        "\n",
        "plt.figure(figsize=(10,5))\n",
        "sns.barplot(counts.index, counts.values, alpha=0.8, palette='bright')\n",
        "plt.title('Distribution of Output Classes')\n",
        "plt.ylabel('Number of Occurrences', fontsize=12)\n",
        "plt.xlabel('Target Classes', fontsize=12)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "k7jDZc3twp_H"
      },
      "source": [
        "# Visualizing Training Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "Ax11I6Zswp_I",
        "outputId": "38d1e936-008b-4703-8ea9-110ed0880eb3"
      },
      "outputs": [],
      "source": [
        "fig = plt.figure(figsize=(30, 6))\n",
        "# display 20 images\n",
        "train_imgs = os.listdir(base_dir+\"/train_images\")\n",
        "for idx, img in enumerate(np.random.choice(train_imgs, 16)):\n",
        "    ax = fig.add_subplot(2, 16//2, idx+1, xticks=[], yticks=[])\n",
        "    im = Image.open(base_dir+\"/train_images/\" + img)\n",
        "    plt.imshow(im)\n",
        "    lab = train_csv.loc[train_csv['id_code'] == img.split('.')[0], 'diagnosis'].values[0]\n",
        "    ax.set_title('Severity: %s'%lab)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "1tw7S3-ywp_L"
      },
      "source": [
        "# Visualizing Test Set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "gmy9BNFwwp_M",
        "outputId": "de5d12e0-c57c-451c-e297-5da3d12a3fbd"
      },
      "outputs": [],
      "source": [
        "fig = plt.figure(figsize=(30, 6))\n",
        "# display 20 images\n",
        "test_imgs = os.listdir(base_dir+\"/test_images\")\n",
        "for idx, img in enumerate(np.random.choice(test_imgs, 16)):\n",
        "    ax = fig.add_subplot(2, 16//2, idx+1, xticks=[], yticks=[])\n",
        "    im = Image.open(base_dir+\"/test_images/\" + img)\n",
        "    plt.imshow(im)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "1ahpFGSqwp_O"
      },
      "source": [
        "# Data Processing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "QfvxpUdcwp_P"
      },
      "outputs": [],
      "source": [
        "# Our own custom class for datasets\n",
        "class CreateDataset(Dataset):\n",
        "    def __init__(self, df_data, data_dir = '../input/', transform=None):\n",
        "        super().__init__()\n",
        "        self.df = df_data.values\n",
        "        self.data_dir = data_dir\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.df)\n",
        "    \n",
        "    def __getitem__(self, index):\n",
        "        img_name,label = self.df[index]\n",
        "        img_path = os.path.join(self.data_dir, img_name+'.png')\n",
        "        image = cv2.imread(img_path)\n",
        "        if self.transform is not None:\n",
        "            image = self.transform(image)\n",
        "        return image, label"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "usFGpYV9wp_R"
      },
      "outputs": [],
      "source": [
        "train_transforms = transforms.Compose([\n",
        "    transforms.ToPILImage(),\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.RandomHorizontalFlip(p=0.4),\n",
        "    #transforms.ColorJitter(brightness=2, contrast=2),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225))\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "3LvQYjjzwp_U"
      },
      "outputs": [],
      "source": [
        "test_transforms = transforms.Compose([transforms.Resize(256),\n",
        "                                      transforms.CenterCrop(224),\n",
        "                                      transforms.ToTensor(),\n",
        "                                      transforms.Normalize([0.485, 0.456, 0.406],[0.229, 0.224, 0.225])])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "mF_yP6FVwp_W"
      },
      "outputs": [],
      "source": [
        "train_path = \"../input/aptos2019-blindness-detection/train_images/\"\n",
        "test_path = \"../input/aptos2019-blindness-detection/test_images/\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "rkUVBpU7wp_Z"
      },
      "outputs": [],
      "source": [
        "train_data = CreateDataset(df_data=train_csv, data_dir=train_path, transform=train_transforms)\n",
        "test_data = CreateDataset(df_data=test_csv, data_dir=test_path, transform=test_transforms)\n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "BE_W-n38wp_c"
      },
      "outputs": [],
      "source": [
        "valid_size = 0.2\n",
        "num_train = len(train_data)\n",
        "indices = list(range(num_train))\n",
        "np.random.shuffle(indices)\n",
        "split = int(np.floor(valid_size * num_train))\n",
        "train_idx, valid_idx = indices[split:], indices[:split]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "i14OtQz0wp_e"
      },
      "outputs": [],
      "source": [
        "train_sampler = SubsetRandomSampler(train_idx)\n",
        "valid_sampler = SubsetRandomSampler(valid_idx)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "oSPMv1iewp_h"
      },
      "outputs": [],
      "source": [
        "trainloader = torch.utils.data.DataLoader(train_data, batch_size=64,sampler=train_sampler)\n",
        "validloader = torch.utils.data.DataLoader(train_data, batch_size=64, sampler=valid_sampler)\n",
        "testloader = torch.utils.data.DataLoader(test_data, batch_size=64)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "NvMplySzwp_j",
        "outputId": "4637822a-caa7-4617-91c4-7820badd6978"
      },
      "outputs": [],
      "source": [
        "print(f\"training examples contain : {len(train_data)}\")\n",
        "print(f\"testing examples contain : {len(test_data)}\")\n",
        "\n",
        "print(len(trainloader))\n",
        "print(len(validloader))\n",
        "print(len(testloader))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "I63353zewp_l",
        "outputId": "229d7b10-ecaf-49bd-f25b-81816dab9a5d"
      },
      "outputs": [],
      "source": [
        "# LOAD ONE BATCH OF TESTING SET TO CHECK THE IMAGES AND THEIR LABELS\n",
        "images, labels = next(iter(trainloader))\n",
        "\n",
        "# Checking shape of image\n",
        "print(f\"Image shape : {images.shape}\")\n",
        "print(f\"Label shape : {labels.shape}\")\n",
        "\n",
        "# denormalizing images\n",
        "def imshow(inp, title=None):\n",
        "    \"\"\"Imshow for Tensor.\"\"\"\n",
        "    inp = inp.numpy().transpose((1, 2, 0))\n",
        "    mean = np.array([0.485, 0.456, 0.406])\n",
        "    std = np.array([0.229, 0.224, 0.225])\n",
        "    inp = std * inp + mean\n",
        "    inp = np.clip(inp, 0, 1)\n",
        "    plt.imshow(inp)\n",
        "    if title is not None:\n",
        "        plt.title(title)\n",
        "    plt.pause(0.001)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "UJC-bbEGwp_o",
        "outputId": "420d0427-7736-460b-82da-37015f8ee195"
      },
      "outputs": [],
      "source": [
        "# plotting the images of loaded batch with given fig size and frame data    \n",
        "import torchvision\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "grid = torchvision.utils.make_grid(images, nrow = 20, padding = 2)\n",
        "plt.figure(figsize = (20, 20))  \n",
        "plt.imshow(np.transpose(grid, (1, 2, 0)))   \n",
        "print('labels:', labels)    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "LJ9C48WYwp_s",
        "outputId": "4ebc2eea-87bd-418f-fb96-cccd50d0e62d"
      },
      "outputs": [],
      "source": [
        "class_names = ['No DR', 'Mild', 'Moderate', 'Severe', 'Proliferative DR']\n",
        "\n",
        "images, labels = next(iter(trainloader))\n",
        "out = torchvision.utils.make_grid(images)\n",
        "imshow(out, title=[class_names[x] for x in labels])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "jqPov202wp_w",
        "outputId": "67396e4a-21e5-4007-d67b-1d913cddcdab"
      },
      "outputs": [],
      "source": [
        "train_on_gpu = torch.cuda.is_available()\n",
        "\n",
        "if not train_on_gpu:\n",
        "    print('CUDA is not available.  Training on CPU ...')\n",
        "else:\n",
        "    print('CUDA is available!  Training on GPU ...')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "YWTE2JVxwp_1"
      },
      "outputs": [],
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "model = models.resnet152(pretrained=True) \n",
        "\n",
        "num_ftrs = model.fc.in_features \n",
        "out_ftrs = 5 \n",
        "  \n",
        "model.fc = nn.Sequential(nn.Linear(num_ftrs, 512),nn.ReLU(),nn.Linear(512,out_ftrs),nn.LogSoftmax(dim=1))\n",
        "\n",
        "criterion = nn.NLLLoss()\n",
        "optimizer = torch.optim.Adam(filter(lambda p:p.requires_grad,model.parameters()) , lr = 0.00001) \n",
        "\n",
        "scheduler = lr_scheduler.StepLR(optimizer, step_size=5, gamma=0.1)\n",
        "model.to(device);"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "v4Hn2lk4wp_4"
      },
      "outputs": [],
      "source": [
        "model_save_name = 'classifier.pt'\n",
        "path = F\"/kaggle/working/{model_save_name}\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "9ETX_27awp_7",
        "outputId": "b7d030e9-e9bb-4dde-d592-0c8c50167d6f"
      },
      "outputs": [],
      "source": [
        "# to unfreeze more layers \n",
        "for name,child in model.named_children():\n",
        "  if name in ['layer2','layer3','layer4','fc']:\n",
        "    print(name + 'is unfrozen')\n",
        "    for param in child.parameters():\n",
        "      param.requires_grad = True\n",
        "  else:\n",
        "    print(name + 'is frozen')\n",
        "    for param in child.parameters():\n",
        "      param.requires_grad = False"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "iOF-Abo-wp_-"
      },
      "outputs": [],
      "source": [
        "optimizer = torch.optim.Adam(filter(lambda p:p.requires_grad,model.parameters()) , lr = 0.000001) \n",
        "scheduler = lr_scheduler.StepLR(optimizer, step_size=5, gamma=0.1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "G0sprIg3wqAB"
      },
      "outputs": [],
      "source": [
        "def load_model(path):\n",
        "  checkpoint = torch.load(path)\n",
        "  model.load_state_dict(checkpoint['model_state_dict'])\n",
        "  optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
        "  return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "7gndNUYIwqAD"
      },
      "outputs": [],
      "source": [
        "model = load_model(\"../input/kernel4f121f3247/classifier.pt\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "JBtQWIRFwqAF",
        "outputId": "c75dfe78-b90b-435e-8edb-4aaf6d011f07"
      },
      "outputs": [],
      "source": [
        "model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "3LIwOcNzwqAH",
        "outputId": "fc685b55-eaa3-4e71-b55b-51a0c43f19eb"
      },
      "outputs": [],
      "source": [
        "pytorch_total_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "print(\"Number of trainable parameters: \\n{}\".format(pytorch_total_params))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "rHB2XhSzwqAK"
      },
      "outputs": [],
      "source": [
        "def train_and_test(e):\n",
        "    epochs = e\n",
        "    train_losses , test_losses, acc = [] , [], []\n",
        "    valid_loss_min = np.Inf \n",
        "    model.train()\n",
        "    print(\"Model Training started.....\")\n",
        "    for epoch in range(epochs):\n",
        "      running_loss = 0\n",
        "      batch = 0\n",
        "      for images , labels in trainloader:\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(images)\n",
        "        loss = criterion(outputs,labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        running_loss += loss.item()\n",
        "        batch += 1\n",
        "        if batch % 10 == 0:\n",
        "            print(f\" epoch {epoch + 1} batch {batch} completed\") \n",
        "      test_loss = 0\n",
        "      accuracy = 0\n",
        "      with torch.no_grad():\n",
        "        print(f\"validation started for {epoch + 1}\")\n",
        "        model.eval() \n",
        "        for images , labels in validloader:\n",
        "          images, labels = images.to(device), labels.to(device)\n",
        "          logps = model(images) \n",
        "          test_loss += criterion(logps,labels) \n",
        "          ps = torch.exp(logps)\n",
        "          top_p , top_class = ps.topk(1,dim=1)\n",
        "          equals = top_class == labels.view(*top_class.shape)\n",
        "          accuracy += torch.mean(equals.type(torch.FloatTensor))\n",
        "      train_losses.append(running_loss/len(trainloader))\n",
        "      test_losses.append(test_loss/len(validloader))\n",
        "      acc.append(accuracy)\n",
        "      scheduler.step()\n",
        "      print(\"Epoch: {}/{}.. \".format(epoch+1, epochs),\"Training Loss: {:.3f}.. \".format(running_loss/len(trainloader)),\"Valid Loss: {:.3f}.. \".format(test_loss/len(validloader)),\n",
        "        \"Valid Accuracy: {:.3f}\".format(accuracy/len(validloader)))\n",
        "      model.train() \n",
        "      if test_loss/len(validloader) <= valid_loss_min:\n",
        "        print('Validation loss decreased ({:.6f} --> {:.6f}).  Saving model ...'.format(valid_loss_min,test_loss/len(validloader))) \n",
        "        torch.save({\n",
        "            'epoch': epoch,\n",
        "            'model': model,\n",
        "            'model_state_dict': model.state_dict(),\n",
        "            'optimizer_state_dict': optimizer.state_dict(),\n",
        "            'loss': valid_loss_min\n",
        "            }, path)\n",
        "        valid_loss_min = test_loss/len(validloader)    \n",
        "    print('Training Completed Succesfully !')    \n",
        "    return train_losses, test_losses, acc "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "9X7zW47awqAM",
        "outputId": "d514b4d2-f42e-4991-f326-ec1c68056c6d"
      },
      "outputs": [],
      "source": [
        "train_losses, valid_losses, acc = train_and_test(5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "zq572wFDwqAO",
        "outputId": "b12538f5-6eef-4284-b7af-7bca45cabb9f"
      },
      "outputs": [],
      "source": [
        "%matplotlib inline\n",
        "%config InlineBackend.figure_format = 'retina'\n",
        "\n",
        "plt.plot(train_losses, label='train_')\n",
        "plt.plot(valid_losses, label='Validation loss')\n",
        "plt.xlabel(\"Epochs\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.legend(frameon=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "14JeIrsSwqAR",
        "outputId": "98493497-4844-4615-a872-d9d2e367d412"
      },
      "outputs": [],
      "source": [
        "%matplotlib inline\n",
        "%config InlineBackend.figure_format = 'retina'\n",
        "\n",
        "plt.plot(acc, label='accuracy')\n",
        "plt.legend(\"\")\n",
        "plt.xlabel(\"Epochs\")\n",
        "plt.ylabel(\"accuracy\")\n",
        "plt.legend(frameon=False)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "include_colab_link": true,
      "name": "training.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
